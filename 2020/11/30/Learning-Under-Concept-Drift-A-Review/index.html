<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Learning Under Concept Drift:A Review | Hexo</title><meta name="author" content="John Doe"><meta name="copyright" content="John Doe"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="摘要-概念漂移描述了流数据的基础分布随时间的不可预见的变化。概念漂移研究涉及漂移检测，理解和适应的方法和技术的发展。数据分析表明，如果不解决漂移问题，那么在概念漂移环境中的机器学习将导致学习效果不佳。为了帮助研究人员确定哪些研究主题是重要的，以及如何在数据分析任务中应用相关技术，有必要对概念漂移领域的当前研究进展和趋势进行高质量的指导性审查。另外，由于近年来概念漂移的快速发展，概念漂移下的学习方法">
<meta property="og:type" content="article">
<meta property="og:title" content="Learning Under Concept Drift:A Review">
<meta property="og:url" content="http://example.com/2020/11/30/Learning-Under-Concept-Drift-A-Review/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="摘要-概念漂移描述了流数据的基础分布随时间的不可预见的变化。概念漂移研究涉及漂移检测，理解和适应的方法和技术的发展。数据分析表明，如果不解决漂移问题，那么在概念漂移环境中的机器学习将导致学习效果不佳。为了帮助研究人员确定哪些研究主题是重要的，以及如何在数据分析任务中应用相关技术，有必要对概念漂移领域的当前研究进展和趋势进行高质量的指导性审查。另外，由于近年来概念漂移的快速发展，概念漂移下的学习方法">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg">
<meta property="article:published_time" content="2020-11-30T05:45:22.000Z">
<meta property="article:modified_time" content="2020-12-01T01:57:08.599Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2020/11/30/Learning-Under-Concept-Drift-A-Review/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2020-12-01 09:57:08'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><meta name="generator" content="Hexo 5.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/null" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">16</div></a></div></div></div><hr/></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Hexo</a></span><span id="menus"><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><h1 class="post-title">Learning Under Concept Drift:A Review</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-11-30T05:45:22.000Z" title="Created 2020-11-30 13:45:22">2020-11-30</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-12-01T01:57:08.599Z" title="Updated 2020-12-01 09:57:08">2020-12-01</time></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p><strong>摘要</strong>-概念漂移描述了流数据的基础分布随时间的不可预见的变化。概念漂移研究涉及漂移检测，理解和适应的方法和技术的发展。数据分析表明，如果不解决漂移问题，那么在概念漂移环境中的机器学习将导致学习效果不佳。为了帮助研究人员确定哪些研究主题是重要的，以及如何在数据分析任务中应用相关技术，有必要对概念漂移领域的当前研究进展和趋势进行高质量的指导性审查。另外，由于近年来概念漂移的快速发展，概念漂移下的学习方法已变得非常系统化，从而揭示了文献中未提及的框架。本文回顾了概念漂移相关研究领域的130多种高质量出版物，分析了方法和技术的最新发展，并建立了概念漂移下的学习框架，包括三个主要部分：概念漂移检测，概念漂移理解和概念漂移适应。本文列出并讨论了10个流行的合成数据集和14个可公开获得的基准数据集，用于评估旨在处理概念漂移的学习算法的性能。此外，涵盖并讨论了概念漂移相关的研究方向。通过提供最先进的知识，本次调查将直接支持研究人员对概念漂移下学习领域研究进展的理解。<br>        Abstract—Concept drift describes unforeseeable changes in the underlying distribution of streaming data over time. Concept drift research involves the development of methodologies and techniques for drift detection, understanding, and adaptation. Data analysis has revealed that machine learning in a concept drift environment will result in poor learning results if the drift is not addressed. To help researchers identify which research topics are significant and how to apply related techniques in data analysis tasks, it is necessary that a high quality, instructive review of current research developments and trends in the concept drift field is conducted. In addition, due to the rapid development of concept drift in recent years, the methodologies of learning under concept drift have become noticeably systematic, unveiling a framework which has not been mentioned in literature. This paper reviews over 130 high quality publications in concept drift related research areas, analyzes up-to-date developments in methodologies and techniques, and establishes a framework of learning under concept drift including three main components: concept drift detection, concept drift understanding, and concept drift adaptation. This paper lists and discusses 10 popular synthetic datasets and 14 publicly available benchmark datasets used for evaluating the performance of learning algorithms aiming at handling concept drift. Also, concept drift related research directions are covered and discussed. By providing state-of-the-art knowledge, this survey will directly support researchers in their understanding of research developments in the field of learning under concept drift.</p>
<h2 id="intro"><a href="#intro" class="headerlink" title="intro"></a>intro</h2><p>政府和公司正在生成大量流数据，并且迫切需要高效的数据分析和机器学习技术来支持他们进行预测和决策。但是，新产品，新市场和新客户行为的迅速变化的环境不可避免地导致概念漂移问题的出现。概念漂移意味着模型试图预测的目标变量的统计属性会以无法预料的方式随时间变化[1]。如果发生概念漂移，则过去数据的诱导模式可能与新数据无关，从而导致不良的预测和决策结果。在许多数据驱动的信息系统（例如数据驱动的预警系统和数据驱动的决策支持系统）中，概念漂移现象已被认为是有效性降低的根本原因。在瞬息万变的大数据环境中，如何提供更可靠的数据驱动的预测和决策工具已成为至关重要的问题。<br>        G OVERNMENTS and companies are generating huge amounts of streaming data and urgently need efficient data analytics and machine learning techniques to support them making predictions and decisions. However, the rapidly changing environment of new products, new markets and new customer behaviors inevitably results in the appearance of concept drift problem. Concept drift means that the statistical properties of the target variable, which the model is trying to predict, change over time in unforeseen ways [1]. If the concept drift occurs, the <strong>induced pattern</strong> of past data may not be relevant to the new data, leading to poor predictions and decision outcomes. The phenomenon of concept drift has been recognized as the root cause of <strong>decreased effectiveness</strong> in many data-driven information systems such as data-driven early warning systems and data-driven decision support systems. In an everchanging and big data environment, how to provide more reliable data-driven predictions and decision facilities has become a crucial issue.</p>
<p>概念漂移问题存在于许多现实世界中。如图1所示，可以看到移动电话使用行为的变化。从该图中的条形图中，移动电话使用模式的时间百分比分布已从“音频呼叫”更改为“相机”。然后在过去的二十年中转向“移动互联网”。<br>        Concept drift problem exists in many real-world situations. An example can be seen in the changes of behavior in mobile phone usage, as shown in Fig. 1. From the bars in this figure, the time percentage distribution of the mobile phone usage pattern has changed from “Audio Call” to “Camera” and then to “Mobile Internet” over the past two decades.</p>
<p>最近在概念漂移领域的有吸引力的研究针对更具挑战性的问题，即如何在<strong>非结构化和嘈杂的数据集中准确检测概念漂移</strong>[2]，[3]，如何以<strong>可解释的方式定量理解概念漂移</strong>[4]，[ 5]，以及如何通过适应相关知识[6]，[7]有效应对漂移。<br>        Recent attractive research in the field of concept drift targets more challenging problems, i.e., how to accurately detect concept drift in unstructured and noisy datasets [2], [3], how to quantitatively understand concept drift in a explainable way [4], [5], and how to effectively react to drift by adapting related knowledge [6], [7].</p>
<p>解决这些挑战使预测和决策具有不确定环境中的适应性。通过在一般的数据科学和人工智能中，特别是在模式识别和数据流挖掘中引入概念漂移技术，与机器学习相关的常规研究已得到显着改善。这些新研究在不断变化的环境中增强了类比推理和知识推理的有效性。在此开发过程中形成了一个新主题：自适应数据驱动的预测/决策系统。特别是，在大数据时代，概念漂移是一个非常突出和重要的问题，因为数据类型和数据分布的不确定性是大数据的固有特性。<br>        Solving these challenges endows prediction and decision-making with the adaptability in an uncertain environment. Conventional research related to machine learning has been significantly improved by introducing concept drift techniques in data science and artificial intelligence in general, and in pattern recognition and data stream mining in particular. These new studies enhance the effectiveness of analogical and knowledge reasoning in an ever-changing environment. A new topic is formed during this development: <strong>adaptive data-driven prediction/decision systems</strong>. In particular, concept drift is a highly prominent and significant issue in the context of the big data era because the uncertainty of data types and data distribution is an inherent nature of big data.</p>
<p>传统的机器学习有两个主要组成部分：培训/学习和预测。关于概念漂移的学习研究提出了三个新的组成部分：漂移检测（是否发生漂移），漂移理解（何时，如何，在哪里发生）和漂移适应（对漂移的存在的反应），如图2所示。这些将在第3、4和5节中讨论。<br>        Conventional machine learning has two main components: training/learning and prediction. Research on learning under concept drift presents three new components: <strong>drift detection</strong> (whether or not drift occurs), <strong>drift understanding</strong> (when, how, where it occurs) and <strong>drift adaptation</strong> (reaction to the existence of drift) as shown in Fig. 2. These will be discussed in Sections 3, 4, and 5.</p>
<p>在文献中，详细的概念漂移调查论文[8]于2014年发表，但有意将概念漂移的某些子问题留给其他出版物，例如数据分布更改（PðXÞ）的详细信息，如第2.1节所述。 2015年，又发表了另一篇全面的调查论文[9]，该论文对既有方法和最新方法进行了调查并提供了教程。它从主动和被动两个主要角度提供了有关概念漂移的混合视图。这两份调查报告都很全面，可以很好地介绍概念漂移研究。但是，在过去的三年中，许多新出版物出现了，甚至出现了一种新的漂移检测方法，称为多重假设检验漂移检测。有必要回顾一下过去的研究重点，并给出有关概念漂移的最新研究趋势，这是本调查论文的主要贡献之一。<br>        In literature, a detailed concept drift survey paper [8] was published in 2014 but intentionally left certain sub-problems of concept drift to other publications, such as the details of the data distribution <strong>change</strong> (PðXÞ) as mentioned in their Section 2.1. In 2015, another comprehensive survey paper [9] was published, which surveys and gives tutorial of both the established and the state-of-the-art approaches. It provides a hybrid-view about concept drift from two primary perspectives, <strong>active and passive</strong>. Both survey papers are comprehensive and can be a good introduction to concept drift researching. However, many new publications have become available in the last three years, even a new category of drift detection methods has arisen, named <strong>multiple hypothesis tests drift detection</strong>. It is necessary to review the past research focuses and give the <strong>most recent research trends</strong> about concept drift, which is one of the main contribution of this survey paper.</p>
<p>除了这两个出版物外，四篇相关的调查论文[6]，[7]，[10]，[11]还提供了有关如何解决概念漂移的宝贵见解，但它们的具体研究重点仅在于数据流学习，而不是分析概念漂移适应算法并了解概念漂移。具体而言，论文[7]致力于结合概念漂移的流学习的数据约简，而[6]仅关注调查动态环境中数据流学习的学习集成的发展。 [11]涉及数据流聚类的发展，[10]重点研究数据流学习的当前和未来趋势。因此，当前文献中存在一个空白，需要对概念漂移的已建立和新出现的研究有一个更全面的了解。对概念漂移的三个主要方面的全面回顾：概念漂移检测，理解和适应，如图2所示；并讨论了概念漂移研究的新趋势。<br>        Besides these two publications, four related survey papers [6], [7], [10], [11] have also provided valuable insights into how to address concept drift, but their specific research focus is only on <strong>data stream learning</strong>, rather than analyzing concept drift adaptation algorithms and understanding concept drift. Specifically, paper [7] focuses on <strong>data reduction</strong> for stream learning incorporating concept drift, while [6] only focuses on <strong>investigating the development in learning ensembles for data stream learning</strong> in a dynamic environment. [11] concerns the evolution of data stream clustering, and [10] focuses on investigating the current and future trends of data stream learning. There is therefore a gap in the current literature that requires a fuller picture of established and the new emerged research on concept drift; a comprehensive review of the three major aspects of concept drift: concept drift detection, understanding and adaptation, as shown in Fig. 2; and a discussion about the new trend of concept drift research.</p>
<p>本调查文件中参考文献的选择按照以下步骤进行：</p>
<p>步骤1.发布数据库：Science Direct，ACM数字图书馆，IEEE Xplore和SpringerLink。</p>
<p>步骤2.文章的初步筛选：第一次搜索是基于关键字的。然后，如果文章1）在概念漂移领域提出了新的理论，算法或方法，或2）报告了概念漂移应用，则将其作为参考。</p>
<p>步骤3.文章的结果过滤：在步骤2中选择的文章分为三组：概念漂移检测，理解和适应。根据以下条件再次过滤每个组中的参考文献：1）时间：主要在最近10年内发布，或2）影响：在高质量的期刊/会议上或引用率很高的文献上发布。<br>        The selection of references in this survey paper was performed according to the following steps: </p>
<p>Step 1. Publication database: Science Direct, ACM Digital Library, IEEE Xplore and SpringerLink. </p>
<p>Step 2. Preliminary screening of articles: The first search was based on keywords. The articles were then selected as references if they 1) present new theory, algorithm or methodology in the area of concept drift, or 2) report a concept drift application. </p>
<p>Step 3. <strong>Result filtering for articles</strong>: The articles selected in Step 2 were divided into three groups: concept drift detection, understanding, and adaptation. The references in each group were filtered again, based on 1) Time: published mainly within the last 10 years, or 2) Impact: published in high quality journals/conferences or having high citations.</p>
<p>步骤4.数据集选择：为了帮助读者测试他们的研究结果，本文列出了流行的数据集及其特征，数据集提供者以及如何使用每个数据集。<br>        Step 4. Dataset selection: To help readers test their research results, this paper lists <strong>popular datasets and their characteristics</strong>, the dataset providers, and how each dataset can be used.</p>
<p>完成此过程后，列出了137篇研究文章，10个广泛使用的综合数据集来评估处理概念漂移的学习算法的性能，并列出了14个公开可用且广泛使用的现实世界数据集进行讨论。本文的主要贡献是：<br>        On completion of this process, 137 research articles, <strong>10 widely used synthetic datasets</strong> for evaluating the performance of learning algorithms dealing with concept drift, and <strong>14 publicly available and widely used real-world datasets</strong> were listed for discussion. The main contributions of this paper are:</p>
<p>它从概念上总结了概念漂移研究的成就，并将研究分为三类：概念漂移检测，理解和适应，为概念漂移研究的发展提供了清晰的框架（图2）。 2）提出了一个新的组件，概念漂移理解，用于检索有关何时，如何以及在哪里方面的概念漂移状态的信息。这也在漂移检测和漂移适应之间建立了联系。 3）揭示了几种非常新的概念漂移技术，例如概念漂移下的主动学习和基于模糊能力模型的漂移检测，并确定了涉及概念漂移的相关研究； 4）它通过多个维度系统地检查了两组概念漂移数据集，即合成数据集和真实世界数据集：数据集描述，可用性，漂移类型的适用性和现有应用； 5）它提出了该领域的一些新兴研究主题和潜在研究方向。<br>        It perceptively summarizes concept drift research achievements and clusters the research into three categories: concept drift detection, understanding and adaptation, providing <strong>a clear framework for concept drift research development</strong> (Fig. 2); 2) It proposes a new component, <strong>concept drift understanding</strong>, for retrieving information about the status of concept drift in aspects of <strong>when, how, and where.</strong> This also creates a connection between drift detection and drift adaptation; </p>
<ol start="3">
<li><p>It uncovers several very new concept drift techniques, such as <strong>active learning under concept drift</strong> and <strong>fuzzy competence model-based drift detection</strong>, and identifies related research involving concept drift; </p>
</li>
<li><p>It systematically <strong>examines</strong> two sets of concept drift datasets, Synthetic datasets and Real-world datasets, through multiple dimensions: dataset description, availability , suitability for type of drift, and existing applications; </p>
</li>
<li><p>It suggests several emerging research topics and potential research directions in this area.</p>
</li>
</ol>
<p>本文的其余部分的结构如下。在第2节中，给出并讨论了概念漂移的定义。第三节介绍概念漂移检测的研究方法和算法。第四部分讨论概念漂移理解的研究进展。关于漂移适应（概念漂移反应）的研究结果在第5节中进行了报道。第6节介绍了用于测试概念漂移算法的评估系统和相关数据集。第7节总结了有关概念漂移问题的相关研究。第8节对主要发现和未来研究方向进行了全面分析。<br>        The remainder of this paper is structured as follows. In Section 2, the <strong>definitions of concept drift</strong> are given and discussed. Section 3 presents <strong>research methods and algorithms</strong> in concept drift detection. Section 4 discusses <strong>research developments</strong> in concept drift understanding. Research results on <strong>drift adaptation</strong> (concept drift reaction) are reported in Section 5. Section 6 presents <strong>evaluation systems and related datasets</strong> used to test concept drift algorithms. Section 7 summaries related <strong>research concerning</strong> the concept drift problem. Section 8 presents a comprehensive analysis of <strong>main findings and future research directions</strong>.</p>
<h2 id="PROBLEM-DESCRIPTION"><a href="#PROBLEM-DESCRIPTION" class="headerlink" title="PROBLEM DESCRIPTION"></a>PROBLEM DESCRIPTION</h2><p>This section first gives the <strong>formal definition</strong> and the <strong>sources</strong> of concept drift in Section 2.1. Then, in Section 2.2, the <strong>commonly defined types</strong> of concept drift are introduced.</p>
<h3 id="Concept-drift-definition-and-the-sources"><a href="#Concept-drift-definition-and-the-sources" class="headerlink" title="Concept drift definition and the sources"></a>Concept drift definition and the sources</h3><p>概念漂移是一种现象，其中目标域的统计属性随时间以任意方式变化[3]。最初由[12]提出，其目的是指出噪声数据可能在不同时间转变为非噪声信息。这些变化可能是由无法直接测量的隐藏变量的变化引起的[4]。形式上，概念漂移定义如下：<br>        Concept drift is a phenomenon in which the statistical properties of a target domain change over time in an arbitrary way [3]. It was first proposed by [12] who aimed to point out that noise data may turn to non-noise information at different time. These changes might be caused by changes in hidden variables which cannot be measured directly [4]. Formally , concept drift is defined as follows:</p>
<p>给定时间段[0，t]，表示为S0，t = {d0，…的一组样本。 。 。 ，dt}，其中di =（Xi，yi）是一个观测值（或数据实例），Xii是特征向量，yi是标号，S0，t遵循特定的分布F0，t（X，y）。如果F0，t（X，y）6 = Ft + 1，∞（X，y），记为∃t，则概念漂移发生在时间戳t + 1处：Pt（X，y）6 = Pt + 1（X， y）[2]，[8]，[13]，[14]。<br>        Given a time period [0, t], a set of samples, denoted as S0,t= {d0, . . . , dt}, where di= (Xi, yi) is one observation (or a data instance), Xiis the feature vector, yiis the label, and S0,tfollows a certain distribution F0,t(X, y). Concept drift occurs at timestamp t + 1, if F0,t(X, y) 6= Ft+1,∞(X, y), denoted as ∃t: Pt(X, y) 6= Pt+1(X, y) [2], [8], [13], [14].</p>
<p>许多作者还使用替代名称（例如数据集偏移[15]或概念偏移[1]）定义了概念漂移。在[16]的工作中引入了其他相关术语，作者提出概念漂移或移位只是数据集移位的一个子类别，数据集移位包括协变量移位，先验概率移位和概念移位。这些定义清楚地说明了每个研究主题的研究范围。然而，由于概念漂移通常与协变量漂移和先验概率漂移相关，并且越来越多的出版物[2]，[8]，[13]，[14]将术语“概念漂移”称为“概念漂移”。 ∃t：Pt（X，y）6 ＝ Pt + 1（X，y）。因此，在本次调查中，我们对概念漂移使用了相同的定义。因此，可以将时间t处的概念漂移定义为时间t处X和y的联合概率的变化。由于联合概率Pt（X，y）可以分解为两部分，即Pt（X，y）= Pt（X）×Pt（y | X），因此概念漂移可以由三个来源触发：<br>        Concept drift has also been defined by various authors using alternative names, such as dataset shift [15] or concept shift [1]. Other related terminologies were introduced in [16]’s work, the authors proposed that concept drift or shift is only one subcategory of dataset shift and the dataset shift is consists of covariate shift, prior probability shift and concept shift. These definitions clearly stated the research scope of each research topics. However, since concept drift is usually associated with covariate shift and prior probability shift, and an increasing number of publications [2], [8], [13], [14] refer to the term ”concept drift” as the problem in which ∃t: Pt(X, y) 6= Pt+1(X, y). Therefore, we apply the same definition of concept drift in this survey. Accordingly, concept drift at time t can be defined as the change of joint probability of X and y at time t. Since the joint probability Pt(X, y) can be decomposed into two parts as Pt(X, y) = Pt(X) × Pt(y|X), concept drift can be triggered by three sources:</p>
<p>来源I：Pt（X）6 = Pt + 1（X），而Pt（y | X）= Pt + 1（y | X），也就是说，研究重点是Pt（x）随Pt（y）的漂移| X）保持不变。由于Pt（X）漂移不影响决策边界，因此也被视为虚拟漂移[7]，图3（a）。<br>•来源II：Pt（y | X）6 = Pt + 1（y | X），而Pt（X）= Pt + 1（X），而Pt（X）保持不变。这种漂移将导致决策边界发生变化，并导致学习精度下降，这也称为实际漂移，图3（b）。<br>•源III：源I和源II的混合物，即Pt（X）6 = Pt + 1（X）和Pt（y | X）6 = Pt + 1（y | X）。概念漂移集中于Pt（y | X）和Pt（X）的漂移，因为这两个变化都传达了有关学习环境的重要信息（图3（c））。<br>        Source I: Pt(X) 6= Pt+1(X) while Pt(y|X) = Pt+1(y|X), that is, the research focus is the drift in Pt(X) while Pt(y|X) remains unchanged. Since Pt(X) drift does not affect the decision boundary , it has also been considered as virtual drift [7], Fig. 3(a).<br>• Source II: Pt(y|X) 6= Pt+1(y|X) while Pt(X) = Pt+1(X) while Pt(X) remains unchanged. This drift will cause decision boundary change and lead to learning accuracy decreasing, which is also called actual drift, Fig. 3(b).<br>• Source III: mixture of Source I and Source II, namely Pt(X) 6= Pt+1(X) and Pt(y|X) 6= Pt+1(y|X). Concept drift focus on the drift of both Pt(y|X) and Pt(X), since both changes convey important information about learning environment Fig. 3(c).</p>
<p>图3展示了这些源在二维特征空间中如何彼此不同。源I是特征空间漂移，源II是决策边界漂移。在许多实际应用中，Source I和Source II会同时出现，从而创建Source III<br>        Fig. 3 demonstrates how these sources differ from each other in a two-dimensional feature space. Source I is feature space drift, and Source II is decision boundary drift. In many real-world applications, Source I and Source II occur together, which creates Source III</p>
<h3 id="The-types-of-concept-drift"><a href="#The-types-of-concept-drift" class="headerlink" title="The types of concept drift"></a>The types of concept drift</h3><p>Commonly , concept drift can be distinguished as four types [8] as shown in Fig. 4: </p>
<p>Research into concept drift adaptation in Types 1-3 focuses on how to <strong>minimize the drop in accuracy and achieve the fastest recovery rate</strong> during the concept transformation process. In contrast, the study of Type 4 drift emphasizes the <strong>use of historical concepts</strong>, that is, how to find the <strong>best matched historical concepts</strong> with the shortest time. The new concept may suddenly, incrementally, or gradually <strong>reoccur</strong>.</p>
<p>To better demonstrate the differences between these types, the term <strong>“intermediate concept”</strong> was introduced by [8] to describe the <strong>transformation</strong> between concepts. As mentioned by [4], a concept drift may not only take place at an exact timestamp, but may also <strong>last for a long period</strong>. As a result, intermediate concepts may appear during the transformation as one concept (starting concept) changes to another (ending concept). An intermediate concept can be a <strong>mixture of the starting concept and the ending concept</strong>, like the <strong>incremental drift</strong>, or one of the starting or ending concept, such as the gradual drift.</p>
<h2 id="CONCEPT-DRIFT-DETECTION"><a href="#CONCEPT-DRIFT-DETECTION" class="headerlink" title="CONCEPT DRIFT DETECTION"></a>CONCEPT DRIFT DETECTION</h2><p>This section focuses on summarizing concept drift detection algorithms. Section 3.1 introduces a typical <strong>drift detection framework</strong>. Then, Section 3.2 systematically <strong>reviews and categorizes</strong> drift detection algorithms according to their <strong>implementation</strong> details for each component in the framework. At last, Section 3.3 lists the <strong>state-of-the-art drift detection</strong> algorithms with comparisons of their implementation details.</p>
<h3 id="A-general-framework-for-drift-detection"><a href="#A-general-framework-for-drift-detection" class="headerlink" title="A general framework for drift detection"></a>A general framework for drift detection</h3><p>Drift detection refers to the techniques and mechanisms that <strong>characterize and quantify concept drift</strong> via <strong>identifying change points</strong> or change time intervals [17]. A general framework for drift detection contains four stages, as shown in Fig. 5.</p>
<p>Stage 1 (<strong>Data Retrieval</strong>) aims to retrieve <strong>data chunks from data streams</strong>. Since a single data instance cannot carry enough information to infer the overall distribution [2], knowing how to <strong>organize data chunks</strong> to form a meaningful pattern or knowledge is important in data stream analysis tasks [7]. </p>
<p>Stage 2 (<strong>Data Modeling</strong>) aims to <strong>abstract</strong> the retrieved data and <strong>extract the key features containing sensitive</strong> information, that is, the features of the data that most impact a system if they drift. This stage is optional, because it mainly concerns <strong>dimensionality reduction</strong>, or <strong>sample size reduction</strong>, to meet storage and online speed requirements [4]. </p>
<p>Stage 3 (<strong>Test Statistics Calculation</strong>) is the measurement of <strong>dissimilarity</strong> , or <strong>distance estimation</strong>. It <strong>quantifies</strong> the <strong>severity</strong> of the drift and <strong>forms test statistics for the hypothesis test</strong>. It is considered to be the most challenging aspect of concept drift detection. The problem of how to define an accurate and robust dissimilarity measurement is still an open question. A <strong>dissimilarity measurement</strong> can also be used in clustering evaluation [11], and to determine the dissimilarity between sample sets [18].</p>
<p>Stage 4 <strong>(Hypothesis Test</strong>) uses a specific hypothesis test to evaluate the <strong>statistical significance</strong> of the change observed in Stage 3, or the <strong>p-value</strong>. They are used to determine <strong>drift detection accuracy</strong> by proving the <strong>statistical bounds</strong> of the test statistics proposed in Stage 3. Without Stage 4, the test statistics acquired in Stage 3 are <strong>meaningless</strong> for drift detection, because they cannot determine the <strong>drift confidence interval(置信区间)</strong>, that is, how likely it is that the change is caused by concept drift and not <strong>noise or random sample</strong> selection bias [3]. The most commonly used hypothesis tests are: <strong>estimating the distribution of the test statistics</strong> [19], [20], <strong>bootstrapping</strong> [21], [22], the <strong>permutation</strong> test [3], and <strong>Hoeffding’s inequality-based</strong> bound identification [23].</p>
<p>It is also worth to mention that, without Stage 1, the concept drift detection problem can be considered as a <strong>two-sample test problem</strong> which examines whether the population of two given sample sets are <strong>from the same distribution</strong> [18]. In other words, any <strong>multivariate two-sample test</strong> is an option that can be adopted in Stages 2-4 to detect concept drift [18]. However, in some cases, <strong>the distribution drift may not be included in the</strong> <strong>target features</strong>, therefore the <strong>selection of the target feature</strong> will affect the overall performance of a learning system and is a critical problem in concept drift detection [24].</p>
<h3 id="Concept-drift-detection-algorithms"><a href="#Concept-drift-detection-algorithms" class="headerlink" title="Concept drift detection algorithms"></a>Concept drift detection algorithms</h3><p>This section surveys drift detection methods and algorithms, which are classified into three categories in terms of the test statistics they apply.</p>
<h4 id="Error-rate-based-drift-detection"><a href="#Error-rate-based-drift-detection" class="headerlink" title="Error rate-based drift detection"></a>Error rate-based drift detection</h4><p><strong>PLearner</strong> error rate-based drift detection algorithms form the largest category of algorithms. These algorithms focus on <strong>tracking changes in the online error rate of base classifiers</strong>. If an <strong>increase or decrease</strong> of the error rate is proven to be <strong>statistically significant</strong>, an <strong>upgrade process</strong> (drift alarm) will be triggered.</p>
<p>One of the most-referenced concept drift detection algorithms is the <strong>Drift Detection Method (DDM)</strong> [20]. It was the first algorithm to define the <strong>warning level and drift leve</strong>l for concept drift detection. In this algorithm, <strong>Stage 1</strong> is implemented by a <strong>landmark time window</strong>, as shown in Fig. 6. When a new data instance become available for evaluation, DDM detects whether the <strong>overall online error rate</strong> within the time window has <strong>increased significantly</strong>. If the <strong>confidence level</strong> of the observed error rate change reaches the <strong>warning level</strong>, DDM starts to <strong>build a new learner</strong> while using the old learner for predictions. If the change <strong>reached the drift level</strong>, the old learner will be <strong>replaced</strong> by the new learner for further prediction tasks. To acquire the online error rate, DDM needs a classifier to make the predictions. This process converts <strong>training data to a learning model</strong>, which is considered as the <strong>Stage 2</strong> (Data Modeling). The test statistics in <strong>Stage 3</strong> constitute the <strong>online error rate</strong>. The hypothesis test, Stage 4, is conducted by estimating the distribution of the online error rate and calculating the warning level and drift threshold.</p>
<p>Similar implementations have been adopted and applied in the <strong>Learning with Local Drift Detection</strong> (LLDD) [25], <strong>Early Drift Detection Method</strong> (EDDM) [26], <strong>Heoffding’s inequality based Drift Detection Method</strong> (HDDM) [23], <strong>Fuzzy Windowing Drift Detection Method</strong> (FW-DDM) [5], <strong>Dynamic Extreme Learning Machine</strong> (DELM) [27]. LLDD modifies Stages 3 and 4, dividing the overall drift detection problem into a set of <strong>decision tree node-based drift detection problems</strong>; EDDM improves Stage 3 of DDM using the <strong>distance</strong> between <strong>two correct classifications</strong> to improve the <strong>sensitivity</strong> of drift detection; HDDM modifies Stage 4 using <strong>Hoeffding’s inequality</strong> to identify the <strong>critical region</strong> of a drift; FW-DDM improves Stage 1 of DDM using a <strong>fuzzy time window</strong> instead of a conventional time window to address the <strong>gradual drift problem</strong>; DEML does not change the DDM detection algorithm but uses a <strong>novel base learner</strong>, which is a <strong>single hidden layer feedback neural network</strong> called Extreme Learning Machine (<strong>ELM</strong>) [28] to <strong>improve the adaptation process</strong> after a drift has been confirmed. <strong>EWMA</strong> for Concept Drift Detection (ECDD) [29] takes advantage of the error rate to detect concept drift. ECDD employs the <strong>EWMA chart to track changes in the error rate</strong>. The implementation of Stages 1-3 of ECDD is the same as for DDM, while Stage 4 is different.   ECDD <strong>modifies</strong> the conventional EWMA chart using <strong>a dynamic mean</strong>$\hat{p}<em>{0, t}$  instead of the conventional static mean $p</em>{0},$ where $\hat{p}<em>{0, t}$ is the estimated online error rate within time $[0, t],$ and $p</em>{0}$ implies the theoretical error rate when the learner was initially built. Accordingly, the <strong>dynamic variance</strong> can be <strong>calculated</strong> by $\sigma_{Z_{t}}^{2}=\hat{p}<em>{0, t}\left(1-\hat{p}</em>{0, t}\right) \sqrt{\frac{\lambda}{2-\lambda}\left(1-(1-\lambda)^{2 t}\right)}$ where $\lambda$ controls<br><strong>how much weight is given to more recent data as opposed to older data</strong>, and $\lambda=0.2$ is recommended by the authors.Also, when the test statistic of the conventional EWMA chart is Zt&gt; ˆ p0,t+ 0.5LσZt, ECDD will report a concept <strong>drift warning</strong>; when Zt&gt; ˆ p0,t+ LσZt, ECDD will <strong>report a concept drift</strong>. The <strong>control limits</strong> L is given by the authors through <strong>experimental evaluation</strong>.</p>
<p>In contrast to DDM and other similar algorithms, <strong>Statistical Test of Equal Proportions Detection</strong> (STEPD) [30] detects error rate <strong>change</strong> by comparing the <strong>most</strong> <strong>recent</strong> time window with the <strong>overall time window</strong>, and for each timestamp, there are two time windows in the system, as shown in Fig. $7 .$ The size of the <strong>new window must be defined by the user</strong>. According to $[30],$ the test statistic $\theta_{\text {STEPD }}$ conforms(符合) to standard normal distribution, denoted as $\theta_{\mathrm{STEPD}} \sim \mathcal{N}(0,1) .$ The <strong>significance level</strong> of the warning level and the drift level were suggested as $\alpha_{w}=0.05$ and $\alpha_{d}=0.003$ respectively. As a result, the warning <strong>threshold</strong> and drift <strong>threshold</strong> can be easily calculated.</p>
<p>Another popular two-time window-based drift detection algorithm is ADaptive WINdowing (ADWIN) [31]. Unlike STEPD, ADWIN does not require users to <strong>define the size of the compared windows in advance</strong>; it only needs to specify the <strong>total size</strong> $n$ of a “<strong>sufficiently large</strong>“ window $W$. It then examines <strong>all possible cuts</strong> of $W$ and computes <strong>optimal sub-window</strong> sizes $n_{\text {hist }}$ and $n_{\text {new }}$ according to the rate of change between the two sub-windows $w_{\text {hist }}$ and $w_{\text {new }}$. The <strong>test statistic</strong> is the <strong>difference</strong> of the two sample means $\theta_{\mathrm{ADWIN}}=$ $\left|\hat{\mu}<em>{\mathrm{hist}}-\hat{\mu}</em>{\mathrm{new}}\right| $ An optimal cut is found when the<br>difference exceeds a threshold with a <strong>predefined confidence interval</strong> $\delta .$ The author proved that both the <strong>false positive rate</strong> and <strong>false negative rate</strong> are <strong>bounded</strong> by $\delta .$ It is worth noting that many concept drift adaptation methods/algorithms in the literature <strong>are derived from or combined</strong> with ADWIN, such as $[32]-[35] .$ since their drift detection methods are implemented with almost the same strategy, we will not discuss them in detail.</p>
<h4 id="Data-Distribution-based-Drift-Detection"><a href="#Data-Distribution-based-Drift-Detection" class="headerlink" title="Data Distribution-based Drift Detection"></a>Data Distribution-based Drift Detection</h4><p>The second largest category of drift detection algorithms is <strong>data distribution-based drift detection</strong>. Algorithms of this category use a <strong>distance function/metric</strong> to quantify the <strong>dissimilarity</strong> between the distribution of historical data and the new data. If the dissimilarity is proven to be <strong>statistically significantly different</strong>, the system will trigger a learning model upgradation process. These algorithms address concept drift from the <strong>root sources</strong>, which is the <strong>distribution drift</strong>. Not only can they accurately identify the <strong>time</strong> of drift, they can also provide <strong>location information about the drift</strong>. However, these algorithms are usually reported as <strong>incurring higher computational cost</strong> than the algorithms mentioned in Section 3.2.1 [2]. In addition, these algorithms usually require users to <strong>predefine</strong> the <strong>historical time window</strong> and new data window. The commonly used strategy is two sliding windows with the <strong>historical time window fixed</strong> while sliding the new data window [3], [22], [36], as shown in Fig. 8.</p>
<p>According to the literature, the first formal treatment of change detection in data streams was proposed by [37]. In their study, the authors point out that the most <strong>natural notion of distance between distributions is total variation</strong>, as defined by: $TV\left(P_{1}, P_{2}\right)=2\sup_{E\in \varepsilon}\left|P_{1}(E)-P_{2}(E)\right| $ or equivalently, when the distribution has the <strong>density functions</strong> $f_{1}$ and $f_{2}, d i s t_{L^{1}}=\int\left|f_{1}(x)-f_{2}(x)\right| \mathrm{d} x .$ This provides practical guidance on the <strong>design of a distance function for distribution discrepancy analysis</strong>. Accordingly, [37] roposed a <strong>family of distances</strong>, called <strong>Relativized Discrepancy</strong> $(\mathrm{RD}) .$ The authors also present the <strong>significance</strong> level of the distance <strong>according to the number of data instances</strong>. The bounds on the probabilities of missed <strong>detections and false alarms are theoretically proven</strong>, using <strong>Chernoff bounds and the Vapnik-Chervonenkis dimension</strong>. The authors of [37] do not <strong>propose novel high-dimensional friendly data models for Stage 2</strong> (data modeling); instead, they stress that a suitable model choice is an open question.</p>
<p>Another <strong>typical density-based</strong> drift detection algorithm is the <strong>Information-Theoretic Approach (ITA)</strong> [22]. The intuitive idea underlying this algorithm is to use <strong>kdqTree</strong> to <strong>partition the historical and new data (multi-dimensional) into a set of bins</strong>, denoted as $\mathcal{A}$, and then use KullbackLeibler <strong>divergence</strong> to quantify the <strong>difference of the density</strong> $\theta_{\text {ITA }}$ in each bin. The hypothesis test applied by ITA is bootstrapping by merging $W_{\text {hist }}, W_{\text {new }}$ as $W_{\text {all }}$ and resampling as $W_{\text {hist }}^{\prime} W_{\text {new}}$to recompute the  $\theta_{\text {ITA }}^{\prime}$. Once the estimated probability $P\left(\theta_{\mathrm{ITA}}^{*} \geq \theta_{\mathrm{ITA}}\right)&lt;1-\alpha,$ concept drift is confirmed, where $\alpha$ is the <strong>significant level controlling the sensitivity of drift detection.</strong></p>
<p>Similar distribution-based drift detection methods/algorithms are: Statistical Change Detection for multidimensional data (SCD) [38], Competence Model-based drift detection (CM) [2], a prototype-based classification model for evolving data streams called SyncStream [36], PCA-based change detection framework (PCA-CD) [39], Equal Density Estimation (EDE) [40], Least Squares Density Difference-based Change Detection Test (LSDD-CDT) [21], Incremental version of LSDD-CDT (LSDD-INC) [41] and Local Drift Degree-based Density Synchronized Drift Adaptation (LDD-DSDA) [4].</p>
<h5 id="Multiple-Hypothesis-T-est-Drift-Detection"><a href="#Multiple-Hypothesis-T-est-Drift-Detection" class="headerlink" title="Multiple Hypothesis T est Drift Detection"></a>Multiple Hypothesis T est Drift Detection</h5><p>Multiple hypothesis test drift detection algorithms apply similar techniques to those mentioned in the previous two categories. The novelty of these algorithms is that they use <strong>multiple hypothesis tests</strong> to detect concept drift in different ways. These algorithms can be divided into two groups: 1) <strong>parallel</strong> multiple hypothesis tests; and 2) <strong>hierarchical</strong> multiple hypothesis tests.</p>
<p>The idea of parallel multiple hypothesis drift detection algorithm is demonstrated in Fig. 9. According to the literature, Just-In-Time adaptive classifiers (JIT) [19] is the first algorithm that set multiple drift detection hypothesis in this way. The core idea of <strong>JIT</strong> is to extend the <strong>CUSUM chart, known as the Computational Intelligence-based CUSUM test (CI-CUSUM)</strong>, to detect the <strong>mean change</strong> in the features interested by learning systems. The authors of $[19],$ gave the following four configurations for the drift detection target. <strong>Config1</strong>: the features extracted by <strong>Principal Component Analysis (PCA)</strong>, which removes eigenvalues whose sum is below a <strong>threshold</strong>, e.g. 0.001. <strong>Config2</strong>: PCA extracted features plus one <strong>generic component of the original features $x_{i} ;$</strong> <strong>Config3</strong>: detects the drift <strong>in each $x_{i}$ individually</strong>. <strong>Config4</strong>:detects drift in <strong>all possible combinations</strong> of the feature space $x_{i} .$ The authors stated that Config2 is the preferred setting for most situations, according to their experimentation, and also mentioned that Config1 may have a high <strong>missing</strong> rate, Config3 suffers from a high <strong>false alarm rate</strong>, and Config4 has <strong>exponential computational complexity</strong>. The same drift detection strategy has also been applied in $[42]-[45]$ for concept drift adaptation.</p>
<p>Similar implementations have been applied in Linear Four Rate drift detection (LFR) [46], which maintains and tracks the changes in True Positive rate (TP), True Negative rate (TN), False Positive rate (FP) and False Negative rate (FN) <strong>in an online manner.</strong> The drift detection process also <strong>includes warning and drift levels</strong>.</p>
<p>Another parallel multiple hypothesis drift detection algorithm is <strong>three-layer drift detection</strong>, based on <strong>Information Value and Jaccard similarity</strong> (IV-Jac) [47]. IV-Jac aims to <strong>individually</strong> address the <strong>label drift</strong> $P_{t}(y)$ Layer I, <strong>feature space drift</strong> $P_{t}(X)$ Layer II, and <strong>decision boundary drift</strong> $P_{t}(y \mid X)$ Layer III. It extracts the <strong>Weight of Evidence (WoE) and Information Value (IV)</strong> from the available data and then detects whether a <strong>significant change exists</strong> between the WoE and IV extracted from $W_{\text {hist }}$ and $W_{\text {new }}$ by measuring the contribution to the label for a feature value. The hypothesis test <strong>thresholds</strong> are predefined parameters $\theta_{P_{t}(y)}=\theta_{P_{t}(X)}=\theta_{P_{t}(X \mid y)}=0.5$ by default, which are chosen <strong>empirically</strong>.</p>
<p>Ensemble of Detectors (e-Detector) [48] proposed to detect concept drift <strong>via ensemble of heterogeneous drift detector</strong>. The authors consider two drift detectors are <strong>homogeneous</strong> as if they are equivalent in finding concept drifts, otherwise they are <strong>heterogeneous</strong>. e-Detector <strong>groups</strong> homogeneous drift detectors via a <strong>diversity(多样性) measurement</strong>, named <strong>diversity vector</strong>. For each group, it select the one with the <strong>smallest coefficient of failure</strong> as the base detector to form the ensemble. e-Detector reports concept drift following the <strong>early-find-early-report rule</strong>, which means no matter which base detector detect a drift, the e-Detector reports a drift. Similar strategy has been applied in <strong>drift detection ensemble</strong> (DDE) [49].</p>
<p><strong>Hierarchical drift</strong> detection is an emerging drift detection category that <strong>has a multiple verification schema</strong>.The algorithms in this category usually detect drift using an <strong>existing</strong> method, called the <strong>detection layer</strong>, and then apply an extra hypothesis test, called the <strong>validation layer,</strong> to obtain <strong>a second validation</strong> of the detected drift in a <strong>hierarchical way</strong>. The overall workflow is shown in Fig. 10.</p>
<p>According to the claim made by [50], Hierarchical Change-Detection Tests (HCDTs) is the first attempt to address concept drift using a hierarchical architecture. The <strong>detection layer</strong> can be any existing drift detection method that has a <strong>low drift delay rate</strong> and <strong>low computational burden</strong>. The validation layer will be <strong>activated and deactivated</strong> based on the results returned by the detection layer. The authors recommend two strategies for designing the validation layer: 1) <strong>estimating the distribution of the test statistics by maximizing the likelihood</strong>; 2) adapting <strong>an existing hypothesis test</strong>, such as the Kolmogorov-Smirnov test or the Cramer-Von Mises test.</p>
<p>Hierarchical Linear Four Rate (HLFR) [51] is another recently proposed hierarchical drift detection algorithm. It applies the <strong>drift detection algorithm LFR as the detection layer</strong>. Once a drift is confirmed by the detection layer, the validation layer will be triggered. The validation layer of HLFR is simply a <strong>zero-one loss</strong>, denoted as E, <strong>over the ordered train-test split</strong>. If the estimated zero-one loss exceeds a predefined threshold, η = 0.01, the validation layer will <strong>confirm the drift</strong> and report to the learning system to trigger a model upgradation process.</p>
<p>Two-Stage Multivariate Shift-Detection based on <strong>EWMA</strong> (TSMSD-EWMA) [52] has a very similar implementation, however, the authors do not claim that their method is a hierarchy-based algorithm.</p>
<p>Hierarchical Hypothesis Testing with Classification Uncertainty (HHT-CU) and Hierarchical Hypothesis Testing with Attribute-wise ”Goodness-of-fit” (HHT-AG) are two drift detection algorithms based on <strong>request and reverify strategy</strong> [53]. For HHT-CU, the <strong>detection</strong> layer is a hypotheses test based on Heoffding’s inequality that monitoring the change of the <strong>classification uncertainty measurement</strong>. The validation layer is a <strong>permutation test that evaluates the change of the zero-one loss of the learner</strong>. For HHT-AG, the detection layer is <strong>conducted</strong> based on Kolmogorov-Smirnov (KS) test for each feature distribution. Then HHT-AG validate the potential drift points by requiring true labels of data that come from wnew, and performing d independent twodimensional (2D) KS test with <strong>each feature-label bivariate distribution.</strong> Compare to other drift detection algorithms, HHT-AG can handle concept drift with <strong>less true labels</strong>, which makes it more powerful when dealing with high verification latency</p>
<h3 id="Summary-of-concept-drift-detection-methods-algorithms"><a href="#Summary-of-concept-drift-detection-methods-algorithms" class="headerlink" title="Summary of concept drift detection methods/algorithms"></a>Summary of concept drift detection methods/algorithms</h3><p>TABLE 1 lists the <strong>most popular</strong> concept drift detection methods/algorithms against the general framework summarized in Section 3.1 (Fig. 5). A <strong>comparative study</strong> on eight popular drift detection methods can be found in [54].</p>
<h2 id="CONCEPT-DRIFT-UNDERSTANDING"><a href="#CONCEPT-DRIFT-UNDERSTANDING" class="headerlink" title="CONCEPT DRIFT UNDERSTANDING"></a>CONCEPT DRIFT UNDERSTANDING</h2><p>Drift understanding refers to retrieving concept drift information about “<strong>When</strong>” (the time at which the concept drift occurs and how long the drift lasts), “<strong>How</strong>” (the severity /degree of concept drift), and “Where” (the <strong>drift regions</strong> of concept drift). This status information is the <strong>output</strong> of the drift detection algorithms, and is <strong>used as input for drift adaptation.</strong></p>
<h3 id="The-time-of-concept-drift-occurs-When"><a href="#The-time-of-concept-drift-occurs-When" class="headerlink" title="The time of concept drift occurs (When)"></a>The time of concept drift occurs (When)</h3><p>The most basic function of drift detection is to identify the timestamp when a drift occurs. Recalling the definition of concept drift $\exists t: P_{t}(X, y) \neq P_{t+1}(X, y)$, the variable t represents the time at which a concept drift occurs. In drift detection methods/algorithms, an <strong>alarm signal</strong> is used to indicate whether the concept drift has or has not <strong>occurred</strong> or not at the current timestamp. It is also a signal for a learning system to <strong>adapt to a new concept.</strong> <strong>Accurately identifying the time a drift occurs</strong> is critical to the adaptation process of a learning system; a <strong>delay or a false alarm</strong> will lead to failure of the learning system to track new concepts.</p>
<p>A drift alarm usually has a <strong>statistical guarantee with a predefined false alarm rate</strong>. Error rate-based drift detection algorithms monitor the <strong>performance</strong> of the learning system, based on statistical process control. For example, DDM [20] sends a drift signal when the <strong>learning accuracy</strong> of the learner drops below a predefined threshold, which is chosen by the three-sigma rule [55]. ECCD [29] reports a drift when the <strong>online error rate exceeds the control limit of EWMA</strong>. Most data distribution-based drift detection algorithms report a drift alarm when two data samples <strong>have a statistically significant difference</strong>. PCA-based drift detection [36] outputs a drift signal when the <strong>p-value of the generalized Wilcoxon test statistic</strong> $W_{B F}^{l}$ is significantly large. The method in [3] confirms that a drift has occurred by verifying whether the <strong>empirical competence-based distance</strong> is significantly large through permuataion test.</p>
<p>Taking into account the various drift types, concept drift understanding needs to explore the <strong>start time point, the change period, and the end time point of concept drift</strong>. And these time information could be useful input for the <strong>adaptation process</strong> of the learning system. Howlever the drift timestamp alert in existing drift detection algorithms <strong>is delayed compared to the actual drifting timestamp</strong>, since most drift detectors require a <strong>minimum number of new data to evaluate</strong> the status of the drift, as shown in Fig. 11. The emergence time of the new concept is therefore <strong>still vague</strong>. Some concept drift detection algorithms such as DDM [20], EDDM [26], STEPD [30], and HDDM [23], trigger a <strong>warning level to indicate a drift may have occurred</strong>. The <strong>threshold</strong> used to trigger warning level is a <strong>relaxed condition of the threshold used for the drift level</strong>; for example, the warning level is set p-value to 95% or 2σ, and the drift level is set p-value to 99% or 3σ. The data <strong>accumulated between</strong> the warning level and the drift level are used as the training set for updating a learning model.</p>
<h3 id="The-severity-of-concept-drift-How"><a href="#The-severity-of-concept-drift-How" class="headerlink" title="The severity of concept drift (How)"></a>The severity of concept drift (How)</h3><p>The severity of concept drift refers to using a <strong>quantified</strong> value to measure the <strong>similarity</strong> between the new concept and the previous concept, as shown in Fig. 11. Formally , <strong>the severity of concept drift</strong> can be represented as ∆ = δ(Pt(X, y), Pt+1(X, y)), where <strong>δ</strong> is a function to measure the <strong>discrepancy of two data distributions</strong>, and t is the <strong>timestamp</strong> when the concept drift occurred. ∆ usually is a non-negative value indicating the severity of concept drift. The greater the value of ∆, the larger the severity of the concept drift is.</p>
<p>In general, error rate-based drift detection cannot directly measure the severity of concept drift, because it mainly focuses on monitoring the performance of the learning system, not the changes in the concept itself. However, the <strong>degree of decrease in learning accuracy can be used as an indirect measurement</strong> to indicate the severity of concept drift. If learning accuracy has dropped significantly when drift is observed, this indicates that the new concept is different from the previous one. For example, the severity of concept drift could be reflected by the difference between piand pminin [20], [27], denoted as ∆ ∼ pi− pmin; the difference between overall accuracy ˆ phistand recent accuracy ˆ pnewin [30], expressed as ∆ ∼ ˆ pnew− ˆ phist; and the difference between test statistics in the former window E[ˆXcut] and test statistics in the later window E[ˆYi−cut] [23], denoted as ∆ ∼ E[ˆYi−cut] − E[ˆXcut]. However, the meaning of these differences is not discussed in existing publications. The ability of error rate-based drift detection to output the severity of concept drift is still vague</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">John Doe</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://example.com/2020/11/30/Learning-Under-Concept-Drift-A-Review/">http://example.com/2020/11/30/Learning-Under-Concept-Drift-A-Review/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2020/11/27/A-survey-of-Methods-for-Time-Series/"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">A_survey_of_Methods_for_Time_Series</div></div></a></div></nav></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="/null" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">John Doe</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">16</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div></div><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="card-content"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#intro"><span class="toc-number">1.</span> <span class="toc-text">intro</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PROBLEM-DESCRIPTION"><span class="toc-number">2.</span> <span class="toc-text">PROBLEM DESCRIPTION</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Concept-drift-definition-and-the-sources"><span class="toc-number">2.1.</span> <span class="toc-text">Concept drift definition and the sources</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#The-types-of-concept-drift"><span class="toc-number">2.2.</span> <span class="toc-text">The types of concept drift</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CONCEPT-DRIFT-DETECTION"><span class="toc-number">3.</span> <span class="toc-text">CONCEPT DRIFT DETECTION</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-general-framework-for-drift-detection"><span class="toc-number">3.1.</span> <span class="toc-text">A general framework for drift detection</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Concept-drift-detection-algorithms"><span class="toc-number">3.2.</span> <span class="toc-text">Concept drift detection algorithms</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Error-rate-based-drift-detection"><span class="toc-number">3.2.1.</span> <span class="toc-text">Error rate-based drift detection</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Data-Distribution-based-Drift-Detection"><span class="toc-number">3.2.2.</span> <span class="toc-text">Data Distribution-based Drift Detection</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Multiple-Hypothesis-T-est-Drift-Detection"><span class="toc-number">3.2.2.1.</span> <span class="toc-text">Multiple Hypothesis T est Drift Detection</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Summary-of-concept-drift-detection-methods-algorithms"><span class="toc-number">3.3.</span> <span class="toc-text">Summary of concept drift detection methods&#x2F;algorithms</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CONCEPT-DRIFT-UNDERSTANDING"><span class="toc-number">4.</span> <span class="toc-text">CONCEPT DRIFT UNDERSTANDING</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#The-time-of-concept-drift-occurs-When"><span class="toc-number">4.1.</span> <span class="toc-text">The time of concept drift occurs (When)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#The-severity-of-concept-drift-How"><span class="toc-number">4.2.</span> <span class="toc-text">The severity of concept drift (How)</span></a></li></ol></li></ol></div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2020/11/30/Learning-Under-Concept-Drift-A-Review/" title="Learning Under Concept Drift:A Review"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Learning Under Concept Drift:A Review"/></a><div class="content"><a class="title" href="/2020/11/30/Learning-Under-Concept-Drift-A-Review/" title="Learning Under Concept Drift:A Review">Learning Under Concept Drift:A Review</a><time datetime="2020-11-30T05:45:22.000Z" title="Created 2020-11-30 13:45:22">2020-11-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/11/27/A-survey-of-Methods-for-Time-Series/" title="A_survey_of_Methods_for_Time_Series"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="A_survey_of_Methods_for_Time_Series"/></a><div class="content"><a class="title" href="/2020/11/27/A-survey-of-Methods-for-Time-Series/" title="A_survey_of_Methods_for_Time_Series">A_survey_of_Methods_for_Time_Series</a><time datetime="2020-11-27T02:48:30.000Z" title="Created 2020-11-27 10:48:30">2020-11-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/11/19/%E4%BB%8E%E5%8F%8D%E5%A4%8D%E6%97%A0%E5%B8%B8%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81%E4%B8%AD%E8%BF%9B%E8%A1%8C%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0-%E4%B8%80%E7%A7%8D%E7%94%9F%E6%88%90%E6%96%B9%E6%B3%95/" title="从反复无常的数据流中进行在线学习:一种生成方法"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="从反复无常的数据流中进行在线学习:一种生成方法"/></a><div class="content"><a class="title" href="/2020/11/19/%E4%BB%8E%E5%8F%8D%E5%A4%8D%E6%97%A0%E5%B8%B8%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81%E4%B8%AD%E8%BF%9B%E8%A1%8C%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0-%E4%B8%80%E7%A7%8D%E7%94%9F%E6%88%90%E6%96%B9%E6%B3%95/" title="从反复无常的数据流中进行在线学习:一种生成方法">从反复无常的数据流中进行在线学习:一种生成方法</a><time datetime="2020-11-19T13:01:07.000Z" title="Created 2020-11-19 21:01:07">2020-11-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/11/19/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0advances-and-open-problems-in-Federated-learning/" title="联邦学习综述advances_and_open_problems_in_Federated_learning"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="联邦学习综述advances_and_open_problems_in_Federated_learning"/></a><div class="content"><a class="title" href="/2020/11/19/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0advances-and-open-problems-in-Federated-learning/" title="联邦学习综述advances_and_open_problems_in_Federated_learning">联邦学习综述advances_and_open_problems_in_Federated_learning</a><time datetime="2020-11-19T07:30:07.000Z" title="Created 2020-11-19 15:30:07">2020-11-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/11/19/%E8%AE%B2%E5%BA%A7-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/" title="讲座-联邦学习综述"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="讲座-联邦学习综述"/></a><div class="content"><a class="title" href="/2020/11/19/%E8%AE%B2%E5%BA%A7-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/" title="讲座-联邦学习综述">讲座-联邦学习综述</a><time datetime="2020-11-19T06:20:49.000Z" title="Created 2020-11-19 14:20:49">2020-11-19</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 By John Doe</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        addClass: [200,() => {
          document.querySelectorAll('mjx-container:not([display=\'true\']').forEach( node => {
            const target = node.parentNode
            if (!target.classList.contains('has-jax')) {
              target.classList.add('mathjax-overflow')
            }
          })
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></div></body></html>